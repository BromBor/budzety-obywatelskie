{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b6d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 00:32:38.064051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-27 00:32:38.064119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-12-27 00:32:41.329525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-27 00:32:41.329586: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-27 00:32:41.329606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mlowanie): /proc/driver/nvidia/version does not exist\n",
      "2021-12-27 00:32:41.329841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-27 00:32:50.251753: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1539542016 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from bud_lib import *\n",
    "\n",
    "tqdm.pandas()\n",
    "nlp = Polish()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd193e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('budzet_dataset.csv')\n",
    "data = data.dropna() #just in case\n",
    "data = data.head(10)\n",
    "sentences = data[\"sentence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647eaf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee7ca6e420147deaebb71a30540be45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"tok\"] = data[\"sentence\"].progress_apply( lambda x: np.array([token.text for token in nlp(x)]))\n",
    "all_tokens = np.concatenate(data[\"tok\"].values)\n",
    "del data[\"tok\"] # no need to store tokenized sentences\n",
    "\n",
    "#pick 300 most common tokens\n",
    "unique, counts = np.unique(all_tokens, return_counts=True)\n",
    "tokens_cnt = dict(zip(unique, counts))\n",
    "tokens_cnt = dict(reversed(sorted(tokens_cnt.items(), key=lambda item: item[1])))\n",
    "tokens_cnt = list(tokens_cnt.items())[:300]\n",
    "topics = np.array([i for i in tokens_cnt])\n",
    "topic_words = np.array([i[0] for i in topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052d753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ed8b403a2a4159b33649927b3dbca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embed_list(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9036c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=20, random_state=0).fit(embeddings)\n",
    "prediction = gm.predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131fd444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['architektura']\n",
      "\n",
      "\n",
      "['atrakcyjność', 'koncentracja']\n",
      "\n",
      "\n",
      "['bohater', 'dorosły', 'senior', 'wieżowiec']\n",
      "\n",
      "\n",
      "['bujny', 'niski', 'skwer']\n",
      "\n",
      "\n",
      "['chodnik', 'ogród', 'park', 'pergola']\n",
      "\n",
      "\n",
      "['doposażyć', 'ligać', 'montaż', 'nasadzić']\n",
      "\n",
      "\n",
      "['dziecko', 'dąbek']\n",
      "\n",
      "\n",
      "['dzielnicowy', 'towarzyski']\n",
      "\n",
      "\n",
      "['elementy', 'mebel', 'ozdobny', 'ławka']\n",
      "\n",
      "\n",
      "['festyn']\n",
      "\n",
      "\n",
      "['kontener', 'podwórek']\n",
      "\n",
      "\n",
      "['kurs', 'lekcja', 'taniec', 'wycieczka']\n",
      "\n",
      "\n",
      "['morski']\n",
      "\n",
      "\n",
      "['naukowy', 'roślina', 'źródlany']\n",
      "\n",
      "\n",
      "['odnowić', 'poprawa', 'rozwijać', 'zaprojektować']\n",
      "\n",
      "\n",
      "['oświetleniowy', 'radarowy', 'wyświetlacz']\n",
      "\n",
      "\n",
      "['pamięć', 'prędkość']\n",
      "\n",
      "\n",
      "['piłkarski']\n",
      "\n",
      "\n",
      "['pracownia', 'słup', 'teatr', 'warsztaty']\n",
      "\n",
      "\n",
      "['siłownia']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_in_group =  dict(zip(topic_words.tolist(), prediction))\n",
    "\n",
    "res = defaultdict(list)\n",
    "for key, val in sorted(name_in_group.items()):\n",
    "    res[val].append(key)\n",
    "\n",
    "for i in res:\n",
    "    print(res[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c7c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
